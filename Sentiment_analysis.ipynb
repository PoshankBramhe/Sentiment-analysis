{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WN2ZgaxWauQ"
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "\n",
        "!pip install goose3\n",
        "from goose3 import Goose\n",
        "\n",
        "import string\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('cmudict')\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from nltk.corpus import cmudict\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpPRadJZliIo"
      },
      "outputs": [],
      "source": [
        "g = Goose()\n",
        "\n",
        "url = 'https://insights.blackcoffer.com/ott-platform-and-its-impact-on-the-entertainment-industry-in-future/'\n",
        "\n",
        "article = g.extract(url)\n",
        "\n",
        "title = article.title\n",
        "\n",
        "text = article.cleaned_text\n",
        "\n",
        "full_article = title + text\n",
        "\n",
        "print(full_article)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbWVH6IQmeMB"
      },
      "outputs": [],
      "source": [
        "# tokenize words\n",
        "\n",
        "full_article = full_article.lower()\n",
        "Cleaned_full_article = full_article.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
        "Cleaned_full_article = Cleaned_full_article.replace(\"\\n\",'').replace(\"•\",\"\").replace(\"–\",\"\").split()\n",
        "\n",
        "tokenized_words = Cleaned_full_article\n",
        "# tokenized_words = nlp(Cleaned_full_article)\n",
        "tokenized_words_len = len(tokenized_words)\n",
        "# tokenized_words = tokenized_words.split()\n",
        "\n",
        "print(\"Number of words:-\",tokenized_words_len)\n",
        "print(tokenized_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahnEZslPn2ET"
      },
      "outputs": [],
      "source": [
        "# tokenize sentences\n",
        "\n",
        "tokenized_sentences = sent_tokenize(full_article)\n",
        "tokenized_sentences_count = len(tokenized_sentences)\n",
        "\n",
        "print(\"Number of words:-\",tokenized_sentences_count)\n",
        "print(tokenized_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mdkn3lJgpGNF"
      },
      "outputs": [],
      "source": [
        "StopWords_Generic = open('/content/StopWords_Generic.txt',encoding = \"utf-8\").read()\n",
        "StopWords_Auditor = open('/content/StopWords_Auditor.txt',encoding = \"utf-8\").read()\n",
        "\n",
        "with open('/content/StopWords_Currencies.txt', 'r', encoding='utf-8', errors='ignore') as file:\n",
        "    StopWords_Currencies = file.read()\n",
        "    StopWords_Currencies = StopWords_Currencies.lower()\n",
        "    StopWords_Currencies = StopWords_Currencies.replace(\"|\",\"\").replace(\"\\n\",\"\")\n",
        "    StopWords_Currencies = StopWords_Currencies.strip()\n",
        "\n",
        "StopWords_GenericLong = open('/content/StopWords_GenericLong.txt',encoding = \"utf-8\").read()\n",
        "StopWords_Geographic = open('/content/StopWords_Geographic.txt',encoding = \"utf-8\").read()\n",
        "StopWords_Names = open('/content/StopWords_Names.txt',encoding = \"utf-8\").read()\n",
        "\n",
        "StopWords_Generic = StopWords_Generic.lower()\n",
        "StopWords_Auditor = StopWords_Auditor.lower()\n",
        "StopWords_GenericLong = StopWords_GenericLong.lower()\n",
        "StopWords_Geographic = StopWords_Geographic.lower()\n",
        "StopWords_Names = StopWords_Names.lower()\n",
        "\n",
        "stop_words = StopWords_Currencies + StopWords_Generic + StopWords_Auditor + StopWords_GenericLong + StopWords_Geographic + StopWords_Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvB4QTs2qDS6"
      },
      "outputs": [],
      "source": [
        "# Regular expression pattern to match URLs\n",
        "url_pattern = r'\\b(?:https?|ftp):\\/\\/\\S+|www\\.\\S+||  '\n",
        "\n",
        "stop_words = re.sub(url_pattern,'', stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5u9pnZb-qQJn"
      },
      "outputs": [],
      "source": [
        "# stop words\n",
        "stop_words = stop_words.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfE1S_LUFziz",
        "outputId": "7b6df485-50ca-4fa7-a341-9c94eec8eb79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "334\n"
          ]
        }
      ],
      "source": [
        "# final_words_len\n",
        "\n",
        "final_words = []\n",
        "for word in tokenized_words:\n",
        "  if word not in stop_words:\n",
        "    final_words.append(word)\n",
        "\n",
        "final_words_len = len(final_words)\n",
        "\n",
        "print(final_words_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-atDBis6IjSr"
      },
      "outputs": [],
      "source": [
        "# Positive_words\n",
        "Positive_words = open('/content/positive-words.txt',encoding = \"utf-8\").read()\n",
        "\n",
        "# Negative_words\n",
        "with open('/content/negative-words.txt', 'r', encoding='utf-8', errors='ignore') as file:\n",
        "    Negative_words = file.read()\n",
        "Negative_words = open('/content/negative-words.txt',encoding = \"utf-8\", errors='ignore').read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yM_cNl6I5JL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d246ddb-94a6-433b-d6a4-73aeaf7ad326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52\n"
          ]
        }
      ],
      "source": [
        "# Positive Score\n",
        "\n",
        "final_positive_words = []\n",
        "for word in final_words:\n",
        "  if word in Positive_words:\n",
        "    final_positive_words.append(word)\n",
        "\n",
        "final_positive_words_len = len(final_positive_words)\n",
        "\n",
        "print(final_positive_words_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bigV0mPwKakE",
        "outputId": "73964d9b-37da-4688-efbb-076ef9ea2fbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53\n"
          ]
        }
      ],
      "source": [
        "# Negative Score\n",
        "\n",
        "final_negative_words = []\n",
        "for word in final_words:\n",
        "  if word in Negative_words:\n",
        "    final_negative_words.append(word)\n",
        "\n",
        "final_negative_words_len = len(final_negative_words)\n",
        "\n",
        "print(final_negative_words_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5ozrPpPMH70",
        "outputId": "9c9cc3e7-0e3e-4468-f15d-81e7a15fb769"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polarity Score : -0.009523809433106578\n"
          ]
        }
      ],
      "source": [
        "# Polarity Score\n",
        "\n",
        "# Polarity Score = (Positive Score – Negative Score)/ ((Positive Score + Negative Score) + 0.000001)\n",
        "polarity_score = (final_positive_words_len - final_negative_words_len)/((final_positive_words_len + final_negative_words_len) + 0.000001)\n",
        "print(\"Polarity Score :\",polarity_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHfRC2I7OGkc",
        "outputId": "eca67dea-e38f-4b58-e5e1-802d1a6cd2dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subjectivity Score : 0.31437125654379866\n"
          ]
        }
      ],
      "source": [
        "# Subjectivity Score\n",
        "\n",
        "# Subjectivity Score = (Positive Score + Negative Score)/ ((Total Words after cleaning) + 0.000001)\n",
        "subjectivity_score = (final_positive_words_len + final_negative_words_len)/((final_words_len) + 0.000001)\n",
        "print(\"Subjectivity Score :\",subjectivity_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh-V6v4OOxPy",
        "outputId": "1b87f8d4-d621-4d8c-cb48-27fe322cd212"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sentence Length : 8.789473684210526\n"
          ]
        }
      ],
      "source": [
        "# Average Sentence Length\n",
        "\n",
        "# Average Sentence Length = the number of words / the number of sentences\n",
        "average_sentence_length = final_words_len / tokenized_sentences_count\n",
        "print(\"Average Sentence Length :\",average_sentence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKWQbgyxP6l8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db09a48e-8767-43d7-e14b-efc72309376f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126\n"
          ]
        }
      ],
      "source": [
        "def count_syllables(word):\n",
        "    try:\n",
        "        d = cmudict.dict()\n",
        "        syllables = [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
        "        return syllables\n",
        "    except KeyError:\n",
        "        return 0\n",
        "complex_words = [word for word in final_words if count_syllables(word) > 2]\n",
        "complex_words_len = len(complex_words)\n",
        "print(complex_words_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8GQI6x7O6-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c385bb-34e7-47c4-ebec-7bc6233e4aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of Complex words : 0.3772455089820359\n"
          ]
        }
      ],
      "source": [
        "# Percentage of Complex words\n",
        "\n",
        "# Percentage of Complex words = the number of complex words / the number of words\n",
        "percentage_of_comlex_words = complex_words_len / final_words_len\n",
        "print(\"Percentage of Complex words :\",percentage_of_comlex_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnSw2GAPllV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c768dfa4-e90e-4451-b535-a76bb3c8261f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fog index : 3.6666876772770247\n"
          ]
        }
      ],
      "source": [
        "# Fog Index\n",
        "\n",
        "# Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n",
        "fog_index = 0.4 * (average_sentence_length + percentage_of_comlex_words)\n",
        "print(\"fog index :\",fog_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0EL6adfl14O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a9acd1-aeba-4de3-f1f2-efe2c88381cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average number of words per sentence : 8.789473684210526\n"
          ]
        }
      ],
      "source": [
        "# Average Number of Words Per Sentence\n",
        "\n",
        "# Average Number of Words Per Sentence = the total number of words / the total number of sentences\n",
        "average_number_of_words_per_sentence = final_words_len / tokenized_sentences_count\n",
        "print(\"Average number of words per sentence :\",average_number_of_words_per_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-K5o9jEmlOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e28a9e2-4620-43a9-fcc2-5baab615bef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "complex words count : 126\n"
          ]
        }
      ],
      "source": [
        "# Complex word count\n",
        "\n",
        "print('complex words count :',complex_words_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee3KtrIjmxaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e87a799a-74ee-4aa0-ae5a-a313786488a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final words len : 334\n"
          ]
        }
      ],
      "source": [
        "# Word Count\n",
        "\n",
        "print(\"final words len :\",final_words_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xrip4j_0nB5z"
      },
      "outputs": [],
      "source": [
        "# Syllable per word\n",
        "\n",
        "def count_syllables(word):\n",
        "    vowels = \"aeiou\"\n",
        "    count = 0\n",
        "    prev_char = None\n",
        "\n",
        "    for char in word.lower():\n",
        "        if char in vowels and (prev_char is None or prev_char not in vowels):\n",
        "            count += 1\n",
        "        prev_char = char\n",
        "\n",
        "    if word.endswith(('es', 'ed')):\n",
        "        count -= 1\n",
        "\n",
        "    return count if count > 0 else 1\n",
        "\n",
        "words = final_words\n",
        "\n",
        "syllable_count = {word: count_syllables(word) for word in words}\n",
        "\n",
        "print(\"Syllable count for each word:\")\n",
        "for word, syllables in syllable_count.items():\n",
        "    print(f\"{word}: {syllables}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jldJIEUTp9vQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648adb6d-7a8a-4cd1-f0e1-7b415e93dc48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Personal Pronoun count: 5\n"
          ]
        }
      ],
      "source": [
        "#Personal Pronoun\n",
        "\n",
        "text = ' '.join(tokenized_words)\n",
        "\n",
        "pattern = r'\\b(?:I|we|my|ours|us)(?![a-z])\\b'\n",
        "\n",
        "matches = re.findall(pattern, text, flags=re.IGNORECASE)\n",
        "\n",
        "personal_pronoun_count = len(matches)\n",
        "print(\"Personal Pronoun count:\", personal_pronoun_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSq_U6Clr-jD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3790f65e-a209-4afa-879a-13666da5d81a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Word Length: 6.01792828685259\n"
          ]
        }
      ],
      "source": [
        "# Avg word length\n",
        "\n",
        "total_characters = sum(len(tokenized_words) for tokenized_words in tokenized_words)\n",
        "\n",
        "total_words = len(tokenized_words)\n",
        "\n",
        "average_word_length = total_characters / total_words if total_words > 0 else 0\n",
        "\n",
        "print(\"Average Word Length:\", average_word_length)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}